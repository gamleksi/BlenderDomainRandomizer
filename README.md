# BlenderDomainRandomizer

This repository generates a domain randomized dataset for affordance detection. 

Our method is introduced in Affordance Learning for End-to-End Visuomotor Robot Control (link to arxiv).

We used Blender, an open-source 3D computer graphics software, to generate this dataset. 
Figure 1 shows examples that are generated by our method.
The environment was designed ror a robotic learning task, where the task of a robot arm was
to insert a ball into a cup that is located on a table.

## Setup

This project has been tested with Blender 2.79. [Blender Download](https://www.blender.org/download/).

To install other depedencies run ```pip install -r requirements.txt```.

env.blend contains all the environment meshes (walls, table, lights, clutter, and cup).

The texture and bum map trees are already built in env.blend.

To examine the Blender environment (env.blend) run ```blender env.blend```.

## Generating Samples

To generate affordance samples run ```blender -b env.blend --python src/main.py```. 
To see parameter options run ```blender -b env.blend --python src/main.py -- --tips```. 
Include your desired parameter after ```--```. 

![A light source environment](images/blender_example.jpg?raw=true "Samples of the dataset")

## More in Depth Discussion About our Method

We used Blender's Python API to generate a domain randomized dataset for affordance detection. The Blender Renderer engine was used for rendering. Each sample includes a rendered RGB-D image and a respective affordance image of the mug. Clutter objects are located on the table and their affordances are ignored.

The following features were randomized:   

* Positions, Scales, and textures of the clutter objects, and the mug
* Shape of the mug
* Texture and scale of the table
* Bump map of the walls
* Position, orientation, and the field of view of the Camera
* The number of clutter objects on the table
*The number of lights in the scene

Positions, scales, and rotations of the objects were uniformly sampled. In total, 66 clutter objects were used.

Blender's Node Editor provides a structural method to combine multiple texture transformation operations together.
We utilized it to randomize the textures and the bump maps of the scene.

Figure 2 shows the node structure of the texture randomizer. Two Blender's texture models, Checker and Distorted Noise, were merged. The initial pattern of Checker and Distorted Noise were modified with size and distortion values.
The two colors of the texture models were given by the ColorRamp nodes. Fac values of the ColorRamp nodes determine produced colors. Scaling, Translate, Rotate, and Darken operations modified the merged texture.

![A light source environment](images/node_textures.png?raw=true "Bump Map randomizer")

A similar node structure, as for the texture randomizer, was implemented for the bump map randomizer. 
Figure 3 shows the bum map node tree. 

![A light source environment](images/bump_textures.png?raw=true "Bump Map randomizer")

The transformation and color values of the nodes were modified through Blender's Python API for each sample.


![A light source environment](images/nodes.png?raw=true "Affordances")
In addition, Diffuse reflection, Transfluecny, and Emit values of the objects were randomized.
